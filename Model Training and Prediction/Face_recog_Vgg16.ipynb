{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Face_recog_Vgg16.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMPLcRfVem7mfrkM4zciqUv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"e4ryjEmIHOkZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594191873565,"user_tz":-330,"elapsed":3064,"user":{"displayName":"RADIO SAYS Arpit pathak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1nT5dx322zEe5G3-3ut8qUdlxMwPCl7X9RukKOA=s64","userId":"07591091807578797265"}},"outputId":"1218864c-8eca-48f9-c2b1-624eccd55a75"},"source":["from keras.applications.vgg16 import VGG16\n","from keras.applications.vgg16 import preprocess_input\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Model, Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n","from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n","from keras.layers.normalization import BatchNormalization\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras.optimizers import RMSprop\n","from keras import backend as K\n","from keras.models import load_model\n","import pandas as pd\n","import numpy as np"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"M3BMt7mFHktC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594191876199,"user_tz":-330,"elapsed":1033,"user":{"displayName":"RADIO SAYS Arpit pathak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1nT5dx322zEe5G3-3ut8qUdlxMwPCl7X9RukKOA=s64","userId":"07591091807578797265"}},"outputId":"10867bb0-bc22-42b4-8f74-1427458a09ee"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LyaWrcz9ISyL","colab_type":"text"},"source":["# **Reloading The VGG16 Model and Freezing the Layers**"]},{"cell_type":"code","metadata":{"id":"_iCjeqgBIr9H","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594191881160,"user_tz":-330,"elapsed":2128,"user":{"displayName":"RADIO SAYS Arpit pathak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1nT5dx322zEe5G3-3ut8qUdlxMwPCl7X9RukKOA=s64","userId":"07591091807578797265"}}},"source":["# VGG was designed to work on 224 x 224 pixel input images sizes\n","img_rows, img_cols = 224, 224 \n","\n","# Re-loads the VGG model without the FC layers\n","VGG_16 = VGG16(weights = 'imagenet', \n","                 include_top = False, \n","                 input_shape = (img_rows, img_cols, 3))\n","\n","# Here we freeze the last 4 layers \n","# Layers are set to trainable as True by default\n","for layer in VGG_16.layers:\n","    layer.trainable = False"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w7WVpqxpKs1I","colab_type":"text"},"source":["# Defining a function for additional layers adding at the top of pre-trained model"]},{"cell_type":"code","metadata":{"id":"mMnPhU-5I1Db","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594191883398,"user_tz":-330,"elapsed":995,"user":{"displayName":"RADIO SAYS Arpit pathak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1nT5dx322zEe5G3-3ut8qUdlxMwPCl7X9RukKOA=s64","userId":"07591091807578797265"}}},"source":["def TopModelVGG_16(bottom_model, num_classes):\n","    \"\"\"creates the top or head of the model that will be \n","    placed ontop of the bottom layers\"\"\"\n","\n","    top_model = bottom_model.output\n","    top_model = GlobalAveragePooling2D()(top_model)\n","    top_model = Dense(1024,activation='relu')(top_model)\n","    top_model = Dense(1024,activation='relu')(top_model)\n","    top_model = Dense(512,activation='relu')(top_model)\n","    top_model = Dense(512,activation='relu')(top_model)\n","    top_model = Dense(num_classes,activation='softmax')(top_model)\n","    return top_model"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xaCmB8faLHt3","colab_type":"text"},"source":["# Combining the models and printing the summary"]},{"cell_type":"code","metadata":{"id":"SjXiA5pEK3Fe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":991},"executionInfo":{"status":"ok","timestamp":1594191887396,"user_tz":-330,"elapsed":1553,"user":{"displayName":"RADIO SAYS Arpit pathak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1nT5dx322zEe5G3-3ut8qUdlxMwPCl7X9RukKOA=s64","userId":"07591091807578797265"}},"outputId":"4f120d63-ca1f-4a6d-c4fa-f0c123f70888"},"source":["num_classes = 5  # number of classes or the people whose data is to be inserted\n","\n","FC_Head = TopModelVGG_16(VGG_16, num_classes)\n","\n","model = Model(inputs = VGG_16.input, outputs = FC_Head)\n","\n","print(model.summary())"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 224, 224, 3)       0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","global_average_pooling2d_1 ( (None, 512)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1024)              525312    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1024)              1049600   \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 512)               524800    \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 5)                 2565      \n","=================================================================\n","Total params: 17,079,621\n","Trainable params: 2,364,933\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IfQS04uyLfAj","colab_type":"text"},"source":["# **Importing dataset and using Image generator for Augmentation**"]},{"cell_type":"code","metadata":{"id":"hHZvOQy7LQEi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1594191892831,"user_tz":-330,"elapsed":1397,"user":{"displayName":"RADIO SAYS Arpit pathak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1nT5dx322zEe5G3-3ut8qUdlxMwPCl7X9RukKOA=s64","userId":"07591091807578797265"}},"outputId":"a44c3e25-a9ba-4bd7-cb5d-6cbe3c298c28"},"source":["#path to training data\n","train_data_dir = '/content/drive/My Drive/Internity_Project/Dataset_face/train_data'\n","#path to validation data\n","validation_data_dir = '/content/drive/My Drive/Internity_Project/Dataset_face/val_data'\n","\n","# Let's use some data augmentation \n","train_datagen = ImageDataGenerator(\n","      rescale=1./255,\n","      rotation_range=10,\n","      width_shift_range=0.1,\n","      height_shift_range=0.1,\n","      horizontal_flip=True,\n","      fill_mode='nearest')\n"," \n","validation_datagen = ImageDataGenerator(rescale=1./255)\n"," \n","# set our batch size\n","batch_size = 32\n"," \n","train_generator = train_datagen.flow_from_directory(\n","        train_data_dir,\n","        target_size=(img_rows, img_cols),\n","        batch_size=batch_size,\n","        class_mode='categorical')\n"," \n","validation_generator = validation_datagen.flow_from_directory(\n","        validation_data_dir,\n","        target_size=(img_rows, img_cols),\n","        batch_size=batch_size,\n","        class_mode='categorical')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Found 200 images belonging to 5 classes.\n","Found 25 images belonging to 5 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uRmVqRoYL272","colab_type":"text"},"source":["#  Training the Model"]},{"cell_type":"code","metadata":{"id":"c23O0hGMLxis","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594192326042,"user_tz":-330,"elapsed":395718,"user":{"displayName":"RADIO SAYS Arpit pathak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1nT5dx322zEe5G3-3ut8qUdlxMwPCl7X9RukKOA=s64","userId":"07591091807578797265"}},"outputId":"a334bc3d-57ad-4857-b53e-c8d1cea9dde9"},"source":["#Path where you have to save the model\n","checkpoint = ModelCheckpoint(\"/content/drive/My Drive/Internity_Project/vgg_16_saved_model.h5\",\n","                             monitor=\"val_loss\",\n","                             mode=\"min\",\n","                             save_best_only = True,\n","                             verbose=1)\n","\n","earlystop = EarlyStopping(monitor = 'val_loss', \n","                          min_delta = 0, \n","                          patience = 5,\n","                          verbose = 1,\n","                          restore_best_weights = True)\n","\n","# we put our call backs into a callback list\n","callbacks = [earlystop, checkpoint]\n","\n","# We use a very small learning rate \n","model.compile(loss = 'categorical_crossentropy',\n","              optimizer = RMSprop(lr = 0.001),\n","              metrics = ['accuracy'])\n","\n","# Enter the number of training and validation samples here\n","nb_train_samples = 200\n","nb_validation_samples = 25\n","\n","# We train 50 EPOCHS \n","epochs = 50\n","batch_size = 8\n","\n","history = model.fit_generator(\n","    train_generator,\n","    steps_per_epoch = nb_train_samples // batch_size,\n","    epochs = epochs,\n","    callbacks = callbacks,\n","    validation_data = validation_generator,\n","    validation_steps = nb_validation_samples // batch_size)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","25/25 [==============================] - 22s 893ms/step - loss: 1.7544 - accuracy: 0.3139 - val_loss: 1.4009 - val_accuracy: 0.5600\n","\n","Epoch 00001: val_loss improved from inf to 1.40089, saving model to /content/drive/My Drive/Internity_Project/vgg_16_saved_model.h5\n","Epoch 2/50\n","25/25 [==============================] - 16s 644ms/step - loss: 1.0842 - accuracy: 0.6085 - val_loss: 0.6114 - val_accuracy: 0.7200\n","\n","Epoch 00002: val_loss improved from 1.40089 to 0.61142, saving model to /content/drive/My Drive/Internity_Project/vgg_16_saved_model.h5\n","Epoch 3/50\n","25/25 [==============================] - 16s 644ms/step - loss: 0.6685 - accuracy: 0.7415 - val_loss: 0.3877 - val_accuracy: 0.8800\n","\n","Epoch 00003: val_loss improved from 0.61142 to 0.38770, saving model to /content/drive/My Drive/Internity_Project/vgg_16_saved_model.h5\n","Epoch 4/50\n","25/25 [==============================] - 17s 677ms/step - loss: 0.6039 - accuracy: 0.7830 - val_loss: 0.4747 - val_accuracy: 0.7600\n","\n","Epoch 00004: val_loss did not improve from 0.38770\n","Epoch 5/50\n","25/25 [==============================] - 16s 658ms/step - loss: 0.6709 - accuracy: 0.7557 - val_loss: 0.6377 - val_accuracy: 0.7600\n","\n","Epoch 00005: val_loss did not improve from 0.38770\n","Epoch 6/50\n","25/25 [==============================] - 17s 673ms/step - loss: 0.4561 - accuracy: 0.8475 - val_loss: 0.2768 - val_accuracy: 0.9600\n","\n","Epoch 00006: val_loss improved from 0.38770 to 0.27677, saving model to /content/drive/My Drive/Internity_Project/vgg_16_saved_model.h5\n","Epoch 7/50\n","25/25 [==============================] - 16s 646ms/step - loss: 0.4281 - accuracy: 0.8381 - val_loss: 0.4644 - val_accuracy: 0.8400\n","\n","Epoch 00007: val_loss did not improve from 0.27677\n","Epoch 8/50\n","25/25 [==============================] - 17s 669ms/step - loss: 0.5096 - accuracy: 0.8613 - val_loss: 0.2651 - val_accuracy: 0.8800\n","\n","Epoch 00008: val_loss improved from 0.27677 to 0.26514, saving model to /content/drive/My Drive/Internity_Project/vgg_16_saved_model.h5\n","Epoch 9/50\n","25/25 [==============================] - 16s 644ms/step - loss: 0.6521 - accuracy: 0.8381 - val_loss: 0.3142 - val_accuracy: 0.8800\n","\n","Epoch 00009: val_loss did not improve from 0.26514\n","Epoch 10/50\n","25/25 [==============================] - 17s 670ms/step - loss: 0.2519 - accuracy: 0.9107 - val_loss: 0.3689 - val_accuracy: 0.8400\n","\n","Epoch 00010: val_loss did not improve from 0.26514\n","Epoch 11/50\n","25/25 [==============================] - 16s 625ms/step - loss: 0.2916 - accuracy: 0.9059 - val_loss: 0.2828 - val_accuracy: 0.9200\n","\n","Epoch 00011: val_loss did not improve from 0.26514\n","Epoch 12/50\n","25/25 [==============================] - 17s 661ms/step - loss: 0.3848 - accuracy: 0.8915 - val_loss: 0.1997 - val_accuracy: 0.9600\n","\n","Epoch 00012: val_loss improved from 0.26514 to 0.19972, saving model to /content/drive/My Drive/Internity_Project/vgg_16_saved_model.h5\n","Epoch 13/50\n","25/25 [==============================] - 17s 677ms/step - loss: 0.2409 - accuracy: 0.9313 - val_loss: 0.1790 - val_accuracy: 0.9600\n","\n","Epoch 00013: val_loss improved from 0.19972 to 0.17896, saving model to /content/drive/My Drive/Internity_Project/vgg_16_saved_model.h5\n","Epoch 14/50\n","25/25 [==============================] - 16s 643ms/step - loss: 0.4284 - accuracy: 0.9048 - val_loss: 0.2737 - val_accuracy: 0.9200\n","\n","Epoch 00014: val_loss did not improve from 0.17896\n","Epoch 15/50\n","25/25 [==============================] - 16s 637ms/step - loss: 0.3755 - accuracy: 0.8778 - val_loss: 0.2497 - val_accuracy: 0.9600\n","\n","Epoch 00015: val_loss did not improve from 0.17896\n","Epoch 16/50\n","25/25 [==============================] - 17s 662ms/step - loss: 0.4815 - accuracy: 0.8695 - val_loss: 0.1856 - val_accuracy: 0.9600\n","\n","Epoch 00016: val_loss did not improve from 0.17896\n","Epoch 17/50\n","25/25 [==============================] - 16s 641ms/step - loss: 0.2414 - accuracy: 0.9403 - val_loss: 0.2449 - val_accuracy: 0.8800\n","\n","Epoch 00017: val_loss did not improve from 0.17896\n","Epoch 18/50\n","25/25 [==============================] - 16s 642ms/step - loss: 0.3361 - accuracy: 0.8963 - val_loss: 0.1233 - val_accuracy: 0.9600\n","\n","Epoch 00018: val_loss improved from 0.17896 to 0.12329, saving model to /content/drive/My Drive/Internity_Project/vgg_16_saved_model.h5\n","Epoch 19/50\n","25/25 [==============================] - 17s 677ms/step - loss: 0.6994 - accuracy: 0.8949 - val_loss: 0.2657 - val_accuracy: 0.8400\n","\n","Epoch 00019: val_loss did not improve from 0.12329\n","Epoch 20/50\n","25/25 [==============================] - 17s 669ms/step - loss: 0.0595 - accuracy: 0.9773 - val_loss: 0.1809 - val_accuracy: 0.9600\n","\n","Epoch 00020: val_loss did not improve from 0.12329\n","Epoch 21/50\n","25/25 [==============================] - 16s 642ms/step - loss: 0.2651 - accuracy: 0.9446 - val_loss: 0.2521 - val_accuracy: 0.9600\n","\n","Epoch 00021: val_loss did not improve from 0.12329\n","Epoch 22/50\n","25/25 [==============================] - 17s 661ms/step - loss: 0.1152 - accuracy: 0.9602 - val_loss: 0.2998 - val_accuracy: 0.9200\n","\n","Epoch 00022: val_loss did not improve from 0.12329\n","Epoch 23/50\n","25/25 [==============================] - 16s 646ms/step - loss: 0.9403 - accuracy: 0.8679 - val_loss: 0.2799 - val_accuracy: 0.9600\n","Restoring model weights from the end of the best epoch\n","\n","Epoch 00023: val_loss did not improve from 0.12329\n","Epoch 00023: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3wc94owFNvbE","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}